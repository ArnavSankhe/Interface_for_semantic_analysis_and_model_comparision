{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zFznk3VgvyXj"
      },
      "outputs": [],
      "source": [
        "#pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git --upgrade --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApJVgqQKYeed",
        "outputId": "8f073e40-7214-4169-b36d-eeaa1e874628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 49.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 253 kB 48.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 48.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 58.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 47.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 51.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 40.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 796 kB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.6 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-w5YbdrwQVS",
        "outputId": "224be880-ed40-4e04-ceb1-b7314411fbe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
            "  \"class\": algorithms.Blowfish,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pickle \n",
        "from tkinter import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#import preprocess_kgptalkie as ps\n",
        "import re\n",
        "import gradio as gr\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "O34gMqidwQyQ",
        "outputId": "39ed9eae-30a9-4bf9-b5a0-925082488dc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_clean(x):\\n    x = str(x).lower().replace(\\'\\\\\\', \\'\\').replace(\\'_\\', \\' \\')\\n    x = ps.cont_exp(x)\\n    x = ps.remove_emails(x)\\n    x = ps.remove_urls(x)\\n    x = ps.remove_html_tags(x)\\n    x = ps.remove_accented_chars(x)\\n    x = ps.remove_special_chars(x)\\n    x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\\n    return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "'''\n",
        "def get_clean(x):\n",
        "    x = str(x).lower().replace('\\\\', '').replace('_', ' ')\n",
        "    x = ps.cont_exp(x)\n",
        "    x = ps.remove_emails(x)\n",
        "    x = ps.remove_urls(x)\n",
        "    x = ps.remove_html_tags(x)\n",
        "    x = ps.remove_accented_chars(x)\n",
        "    x = ps.remove_special_chars(x)\n",
        "    x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
        "    return x\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "86ZFTvSmEDe-"
      },
      "outputs": [],
      "source": [
        "def get_clean(x):\n",
        "  x = x.lower()\n",
        "  x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
        "  x = x.encode('ascii', 'ignore').decode()\n",
        "  x = re.sub(r'https*\\S+', ' ', x)\n",
        "  x = re.sub(r'@\\S+', ' ', x)\n",
        "  x = re.sub(r'#\\S+', ' ', x)\n",
        "  x = re.sub(r'\\'\\w+', '', x)\n",
        "  x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
        "  x = re.sub(r'\\s{2,}', ' ', x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eggwoJ1FxBD9"
      },
      "outputs": [],
      "source": [
        "tfidf = pickle.load(open(\"../content/vectorizer.pickle\", 'rb'))\n",
        "loaded_model_linearsvc = pickle.load(open('../content/model', 'rb'))\n",
        "loaded_model_xgb = pickle.load(open('../content/model_xgb', 'rb'))\n",
        "loaded_model_rf = pickle.load(open('../content/model_rf', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QrNuWXZ4xJat"
      },
      "outputs": [],
      "source": [
        "def pre_processing(x):\n",
        "  x = get_clean(x)\n",
        "  vec = tfidf.transform([x])\n",
        "  return vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EprsPTg1XbmH"
      },
      "outputs": [],
      "source": [
        "def classify(num):\n",
        "  if num<0.5:\n",
        "    return 'Neutral'\n",
        "  elif num>=0.5 and num<=1.5:\n",
        "    return 'Positive'\n",
        "  else:\n",
        "    return 'Negative'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "77OT0FrTD-0i"
      },
      "outputs": [],
      "source": [
        "#def average(outputs):\n",
        "#  return sum(outputs) / len(outputs)\n",
        "\n",
        "#average(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QjstFRFQZgr8"
      },
      "outputs": [],
      "source": [
        "def predict(text_to_analyse):\n",
        "  #outputs = []\n",
        "  x = text_to_analyse\n",
        "  vec = pre_processing(x)\n",
        "  LSVC = loaded_model_linearsvc.predict(vec)\n",
        "  output_svc = classify(LSVC)\n",
        "  #outputs.append(num)\n",
        "  XGB  = loaded_model_xgb.predict(vec)\n",
        "  output_xgb = classify(XGB)\n",
        "  #outputs.append(num)\n",
        "  rf = loaded_model_rf.predict(vec)\n",
        "  output_rf = classify(rf)\n",
        "  #outputs.append(num)\n",
        "  output1 = \"The output of LinearSVC is \" + output_svc\n",
        "  output2 = \"The output of XGBoost is \" + output_xgb\n",
        "  output3 = \"The output of Random forest is \" + output_rf\n",
        "  return (output1, output2, output3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ris6qhD6Z6G5"
      },
      "outputs": [],
      "source": [
        "interface = gr.Interface(\n",
        "    fn = predict,\n",
        "    inputs = ['text'],\n",
        "    outputs =  ['text','text','text'],\n",
        "    title=\"TEXT ANALYSIS\",\n",
        "    live = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "zpqA1mKZaZfK",
        "outputId": "88ca9c11-fe49-44b0-8293-f88171d9ea79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://53388.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9c25a30790>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://53388.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<fastapi.applications.FastAPI at 0x7f9c2e380b50>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://53388.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "interface.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code for testing purpose and getting predictions from csv on multiple inputs.** Only run this after uploading the csv"
      ],
      "metadata": {
        "id": "hgl1_7r-kNxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Test_data.csv\")   #input the csv file and copy the location only then run this.\n",
        "df['Input'] = df['Input'].apply(lambda x: get_clean(x))\n",
        "Input_list = df['Input'].tolist()\n",
        "for i in Input_list: \n",
        "  x = i\n",
        "  vec = tfidf.transform([x])\n",
        "  vec.shape\n",
        "  XGB  = loaded_model_xgb.predict(vec)       #Can change the model \n",
        "  output_xgb = classify(XGB)          \n",
        "  print(output_xgb)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAJEpFvEXg53",
        "outputId": "40581ee8-eb65-4f7f-d83e-db95bdf462cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n",
            "Neutral\n",
            "Neutral\n",
            "Negative\n",
            "Neutral\n",
            "Positive\n",
            "Negative\n",
            "Neutral\n",
            "Positive\n",
            "Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DqOwzqs7eNOx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TWk9kqLlePlI"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_ui.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}